{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GudiOP/Challenge-ONE-Telecom-X/blob/main/TelecomX_LATAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üìå Extracci√≥n"
      ],
      "metadata": {
        "id": "4foVEKhrlqcH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup e importaciones"
      ],
      "metadata": {
        "id": "1jEJXa2bsoqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, io, os, re, textwrap, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option('display.max_columns', 100)\n",
        "pd.set_option('display.float_format', lambda x: f'{x:,.3f}')"
      ],
      "metadata": {
        "id": "1--uPM88l7JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "API_URL = None  # p.ej. \"https://api.telecomx.com/v1/churn\"\n",
        "LOCAL_JSON_PATH = \"/content/TelecomX_Data.json\"  # s√∫belo a Colab si no hay API\n",
        "\n",
        "def fetch_json_from_api(url: str, timeout=60):\n",
        "    r = requests.get(url, timeout=timeout)\n",
        "    r.raise_for_status()\n",
        "    return r.json()\n",
        "\n",
        "def load_data():\n",
        "    # 1) API si est√° configurada\n",
        "    if API_URL:\n",
        "        try:\n",
        "            print(\"‚Üí Extrayendo de API...\")\n",
        "            data = fetch_json_from_api(API_URL)\n",
        "            return data\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error API: {e}\")\n",
        "\n",
        "    # 2) Archivo local\n",
        "    if os.path.exists(LOCAL_JSON_PATH):\n",
        "        print(\"‚Üí Cargando JSON local:\", LOCAL_JSON_PATH)\n",
        "        with open(LOCAL_JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    # 3) (Opcional) Pega aqu√≠ un RAW_URL si lo tienes:\n",
        "    RAW_URL = None  # p.ej. \"https://raw.githubusercontent.com/.../TelecomX_Data.json\"\n",
        "    if RAW_URL:\n",
        "        try:\n",
        "            print(\"‚Üí Descargando JSON de GitHub RAW...\")\n",
        "            txt = requests.get(RAW_URL, timeout=60).text\n",
        "            return json.loads(txt)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error RAW: {e}\")\n",
        "\n",
        "    raise FileNotFoundError(\n",
        "        \"No se encontr√≥ fuente de datos. Configura API_URL, sube el JSON a LOCAL_JSON_PATH o define RAW_URL.\"\n",
        "    )\n",
        "\n",
        "raw = load_data()\n",
        "\n",
        "# Si la ra√≠z es una lista de registros, perfecto; si viene anidado, intenta normalizar:\n",
        "if isinstance(raw, list):\n",
        "    df = pd.DataFrame(raw)\n",
        "elif isinstance(raw, dict):\n",
        "    # intento gen√©rico de normalizaci√≥n\n",
        "    # busca la clave que parezca contener los registros\n",
        "    candidate_keys = [k for k, v in raw.items() if isinstance(v, list) and len(v) and isinstance(v[0], dict)]\n",
        "    if candidate_keys:\n",
        "        df = pd.json_normalize(raw[candidate_keys[0]])\n",
        "    else:\n",
        "        # √∫ltimo recurso: normaliza todo\n",
        "        df = pd.json_normalize(raw, max_level=1)\n",
        "else:\n",
        "    raise ValueError(\"Estructura JSON no reconocida.\")\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "WqHStufksug8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üîß Transformaci√≥n"
      ],
      "metadata": {
        "id": "1lSZP8zmmGZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def slugify(s):\n",
        "    s = re.sub(r'[\\s/]+', '_', s.strip(), flags=re.I)\n",
        "    s = re.sub(r'[^a-zA-Z0-9_]+', '', s)\n",
        "    return s.lower()\n",
        "\n",
        "df.columns = [slugify(c) for c in df.columns]\n",
        "\n",
        "# Candidatos a columna target (b√∫squeda flexible)\n",
        "TARGET_CANDIDATES = [\n",
        "    'churn','evade','evasao','evasion','abandono','customer_churn','is_churn',\n",
        "    'churn_flag','churned','cancelled','cancelado','baixa'\n",
        "]\n",
        "target_col = None\n",
        "for c in df.columns:\n",
        "    if any(tc in c for tc in TARGET_CANDIDATES):\n",
        "        target_col = c\n",
        "        break\n",
        "\n",
        "if target_col is None:\n",
        "    print(\"‚ö†Ô∏è No se detect√≥ autom√°ticamente la columna objetivo (churn).\"\n",
        "          \" Ajusta 'target_col' manualmente.\")\n",
        "    # EJEMPLO: target_col = 'churn'\n",
        "else:\n",
        "    print(\"Columna objetivo detectada:\", target_col)\n",
        "\n",
        "# Normalizaci√≥n de booleanos en todo el DF\n",
        "BOOLEAN_LIKE = {\"yes\": True, \"y\": True, \"si\": True, \"s√≠\": True, \"true\": True, \"1\": True,\n",
        "                \"no\": False, \"n\": False, \"false\": False, \"0\": False}\n",
        "for c in df.columns:\n",
        "    if df[c].dtype == object:\n",
        "        df[c] = df[c].astype(str).str.strip()\n",
        "        # intenta mapear a booleano cuando aplique\n",
        "        vals = set(df[c].str.lower().unique())\n",
        "        if vals.issubset(set(BOOLEAN_LIKE.keys())) or len(vals & set(BOOLEAN_LIKE.keys())) >= max(2, int(0.7*len(vals))):\n",
        "            df[c] = df[c].str.lower().map(BOOLEAN_LIKE).astype('boolean')\n",
        "\n",
        "# Conversi√≥n num√©rica conservadora (si es texto con n√∫meros)\n",
        "for c in df.columns:\n",
        "    if df[c].dtype == object:\n",
        "        # intenta parsear a n√∫mero sin romper categor√≠as claras\n",
        "        try_num = pd.to_numeric(df[c].str.replace(',', '', regex=False), errors='coerce')\n",
        "        # Si al menos 70% puede convertirse, tomamos la conversi√≥n\n",
        "        if try_num.notna().mean() >= 0.7:\n",
        "            df[c] = try_num\n",
        "\n",
        "# Quitar duplicados exactos\n",
        "before = len(df)\n",
        "df = df.drop_duplicates()\n",
        "print(f\"Duplicados removidos: {before - len(df)}\")\n",
        "\n",
        "# Reporte post-limpieza\n",
        "quick_profile(df)"
      ],
      "metadata": {
        "id": "bsm-WTLjmHvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üìä Carga y an√°lisis"
      ],
      "metadata": {
        "id": "6XnTC2NTmMRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_bar(series, title, top=10, rotation=30):\n",
        "    counts = series.value_counts(dropna=False).head(top)\n",
        "    plt.figure()\n",
        "    counts.plot(kind='bar')\n",
        "    plt.title(title)\n",
        "    plt.xticks(rotation=rotation)\n",
        "    plt.ylabel(\"Frecuencia\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_hist(series, title, bins=30):\n",
        "    s = pd.to_numeric(series, errors='coerce').dropna()\n",
        "    if len(s):\n",
        "        plt.figure()\n",
        "        plt.hist(s, bins=bins)\n",
        "        plt.title(title)\n",
        "        plt.xlabel(series.name)\n",
        "        plt.ylabel(\"Frecuencia\")\n",
        "        plt.show()\n",
        "\n",
        "def plot_box_by_churn(df, num_col, target):\n",
        "    tmp = df[[num_col, target]].copy()\n",
        "    tmp[target] = tmp[target].astype(str)\n",
        "    plt.figure()\n",
        "    # boxplot por clase de churn\n",
        "    groups = [tmp[tmp[target]==cls][num_col].dropna().values for cls in tmp[target].unique()]\n",
        "    plt.boxplot(groups, labels=tmp[target].unique())\n",
        "    plt.title(f\"{num_col} por {target}\")\n",
        "    plt.xlabel(target)\n",
        "    plt.ylabel(num_col)\n",
        "    plt.show()\n",
        "\n",
        "# 6.1 Distribuciones de columnas categ√≥ricas y num√©ricas\n",
        "cat_cols = [c for c in df.columns if df[c].dtype == 'object' or str(df[c].dtype).startswith('bool')]\n",
        "num_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
        "\n",
        "for c in cat_cols[:8]:\n",
        "    plot_bar(df[c], f\"Distribuci√≥n de {c}\")\n",
        "\n",
        "for c in num_cols[:8]:\n",
        "    plot_hist(df[c], f\"Histograma de {c}\")\n",
        "\n",
        "# 6.2 Churn por categor√≠a (Top k categor√≠as con mayor churn)\n",
        "if target_col is not None:\n",
        "    def churn_by_category(_df, col, target):\n",
        "        g = _df.groupby(col)[target].apply(lambda s: (s.astype(str).str.lower()\n",
        "                                                      .isin(['1','true','yes','y','si','s√≠']).mean()))\n",
        "        return g.sort_values(ascending=False)\n",
        "\n",
        "    insights_cat = {}\n",
        "    for c in cat_cols:\n",
        "        if c == target_col:\n",
        "            continue\n",
        "        try:\n",
        "            g = churn_by_category(df, c, target_col)\n",
        "            insights_cat[c] = g\n",
        "            plt.figure()\n",
        "            g.head(10).plot(kind='bar')\n",
        "            plt.title(f\"Churn por {c} (Top 10)\")\n",
        "            plt.xticks(rotation=30)\n",
        "            plt.ylabel(\"Tasa de churn\")\n",
        "            plt.show()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "# 6.3 Churn vs. num√©ricos (boxplots)\n",
        "if target_col is not None:\n",
        "    for c in num_cols[:8]:\n",
        "        try:\n",
        "            plot_box_by_churn(df, c, target_col)\n",
        "        except Exception:\n",
        "            pass"
      ],
      "metadata": {
        "id": "1jgUnLqTmPdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üìÑInforme final"
      ],
      "metadata": {
        "id": "v-WzfSvTmaw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conclusions_template(df, target):\n",
        "    lines = []\n",
        "    n = len(df)\n",
        "    if target is not None and target in df.columns:\n",
        "        y = df[target].astype(str).str.lower().isin(['1','true','yes','y','si','s√≠']).astype(float)\n",
        "        churn = y.mean()\n",
        "        lines.append(f\"- Muestra analizada: {n:,} clientes.\")\n",
        "        lines.append(f\"- Tasa general de churn: {churn:.2%}.\")\n",
        "    else:\n",
        "        lines.append(f\"- Muestra analizada: {n:,} registros. (Definir columna objetivo para tasa de churn)\")\n",
        "\n",
        "    # Top drivers si fueron calculados\n",
        "    try:\n",
        "        top5 = drivers.head(5).copy()\n",
        "        top5['support'] = (top5['support']*100).round(1).astype(str) + '%'\n",
        "        top5['churn_rate'] = (top5['churn_rate']*100).round(1).astype(str) + '%'\n",
        "        lines.append(\"- Posibles factores asociados (EDA, no causalidad):\")\n",
        "        for _, r in top5.iterrows():\n",
        "            lines.append(f\"  ‚Ä¢ {r['feature']} = {r['value']}  ‚Üí churn {r['churn_rate']} (soporte {r['support']})\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    txt = \"\\n\".join(lines + [\n",
        "        \"\",\n",
        "        \"Recomendaciones iniciales (hip√≥tesis a validar):\",\n",
        "        \"1) Priorizar retenci√≥n en segmentos con churn alto y soporte significativo.\",\n",
        "        \"2) Revisar fricciones de experiencia (soporte, facturaci√≥n, portabilidad, fallas t√©cnicas).\",\n",
        "        \"3) Evaluar impacto de tipo de contrato, m√©todo de pago y servicios adicionales en la evasi√≥n.\",\n",
        "        \"4) Probar ofertas/beneficios para clientes en riesgo (cross-sell/upgrade, descuentos por permanencia).\",\n",
        "        \"5) Entregar dataset 'model_ready' al equipo de Ciencia de Datos para modelado predictivo.\"\n",
        "    ])\n",
        "    return txt\n",
        "\n",
        "print(conclusions_template(df, target_col))"
      ],
      "metadata": {
        "id": "XMTac0YJmeK9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}